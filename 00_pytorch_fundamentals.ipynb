{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxsMYJEkjCrZ0OD2Gsy5XT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiayinjx/pytorch-machine-learning/blob/main/00_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 00.PyTorch Fundamentals"
      ],
      "metadata": {
        "id": "2Bh9G6kEFKBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "| **Topic** | **Contents** |\n",
        "| ----- | ----- |\n",
        "| **Introduction to tensors** | Tensors are the basic building block of all of machine learning and deep learning. |\n",
        "| **Creating tensors** | Tensors can represent almost any kind of data (images, words, tables of numbers). |\n",
        "| **Getting information from tensors** | If you can put information into a tensor, you'll want to get it out too. |\n",
        "| **Manipulating tensors** | Machine learning algorithms (like neural networks) involve manipulating tensors in many different ways such as adding, multiplying, combining. |\n",
        "| **Dealing with tensor shapes** | One of the most common issues in machine learning is dealing with shape mismatches (trying to mixed wrong shaped tensors with other tensors). |\n",
        "| **Indexing on tensors** | If you've indexed on a Python list or NumPy array, it's very similar with tensors, except they can have far more dimensions. |\n",
        "| **Mixing PyTorch tensors and NumPy** | PyTorch plays with tensors ([`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html)), NumPy likes arrays ([`np.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html)) sometimes you'll want to mix and match these. |\n",
        "| **Reproducibility** | Machine learning is very experimental and since it uses a lot of *randomness* to work, sometimes you'll want that *randomness* to not be so random. |\n",
        "| **Running tensors on GPU** | GPUs (Graphics Processing Units) make your code faster, PyTorch makes it easy to run your code on GPUs. |\n"
      ],
      "metadata": {
        "id": "HJGrTatDeVG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing PyTorch\n",
        "\n",
        "> [PyTorch setup steps](https://pytorch.org/get-started/locally/).\n",
        ">\n",
        "> **Running on Google Colab** (Google Colab comes with PyTorch and other libraries installed)."
      ],
      "metadata": {
        "id": "s0Ov6Ri3f84m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7pT4d9PFNUm",
        "outputId": "ac293bcb-d533-4801-de8d-719eb59be0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 22 16:51:47 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch==2.1.2+rocm5.6 torchvision==0.16.2+rocm5.6 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIndJq4rHCpv",
        "outputId": "d32a9acf-a41b-4fee-c433-1cbc6a47ddd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==2.1.2+rocm5.6\n",
            "  Using cached https://download.pytorch.org/whl/rocm5.6/torch-2.1.2%2Brocm5.6-cp310-cp310-linux_x86_64.whl (1590.3 MB)\n",
            "Collecting torchvision==0.16.2+rocm5.6\n",
            "  Downloading https://download.pytorch.org/whl/rocm5.6/torchvision-0.16.2%2Brocm5.6-cp310-cp310-linux_x86_64.whl (65.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2+rocm5.6) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2+rocm5.6) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2+rocm5.6) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2+rocm5.6) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2+rocm5.6) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2+rocm5.6) (2023.6.0)\n",
            "Collecting pytorch-triton-rocm==2.1.0 (from torch==2.1.2+rocm5.6)\n",
            "  Downloading pytorch_triton_rocm-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.2+rocm5.6) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.2+rocm5.6) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.2+rocm5.6) (9.4.0)\n",
            "Requirement already satisfied: cmake>=3.20 in /usr/local/lib/python3.10/dist-packages (from pytorch-triton-rocm==2.1.0->torch==2.1.2+rocm5.6) (3.27.9)\n",
            "Collecting lit (from pytorch-triton-rocm==2.1.0->torch==2.1.2+rocm5.6)\n",
            "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2+rocm5.6) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2+rocm5.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2+rocm5.6) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2+rocm5.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2+rocm5.6) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2+rocm5.6) (1.3.0)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=f742038844955556d3173f5aaea70304b35bca841dc72b0ac665270b21c15a38\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n",
            "Successfully built lit\n",
            "Installing collected packages: lit, pytorch-triton-rocm, torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.16.0+cu121\n",
            "    Uninstalling torchvision-0.16.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.16.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.1.2+rocm5.6 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2+rocm5.6 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2+rocm5.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-17.0.6 pytorch-triton-rocm-2.1.0 torch-2.1.2+rocm5.6 torchvision-0.16.2+rocm5.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGC1QtP4Gb4e",
        "outputId": "8edc96b5-dbb2-4ee1-ae12-4a86b106034b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Tensor\n",
        "\n",
        "\n",
        "**Tensors** are the fundamental building block of machine learning.\n",
        "- To represent data in a numerical way.\n",
        "- Example: to represent an image as a tensor with shape `[3, 224, 224]` which would mean `[color_channels, height, width]`, as in the image has `3` color channels (red, green, blue), a height of `224` pixels and a width of `224` pixels.\n",
        "\n",
        "![example of going from an input image to a tensor representation of the image, image gets broken down into 3 colour channels as well as numbers to represent the height and width](https://raw.githubusercontent.com/jiayinjx/pytorch-machine-learning/main/images/00-tensor-shape-example-of-image.png)\n",
        "\n",
        "In tensor-speak (the language used to describe tensors), the tensor would have three dimensions, one for `color_channels`, `height` and `width`.\n",
        "\n"
      ],
      "metadata": {
        "id": "CS3tuFSdH3_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating tensors\n",
        "PyTorch tensors are created using `torch.Tensor()` = https://pytorch.org/docs/stable/tensors.html\n",
        "\n",
        "#### Create a Scalar\n",
        "A **scalar** is a single number and in tensor-speak it's a zero dimension tensor.\n"
      ],
      "metadata": {
        "id": "ruxtrm2yhcus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r4fsdgCH_p7",
        "outputId": "44cfd24a-7a42-40f4-9b19-799aab527e0e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The printed out `tensor(7)` means although `scalar` is a single number, it's of type `torch.Tensor`."
      ],
      "metadata": {
        "id": "6ZFo3KE-i0dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the dimensions of a tensor using the `ndim` attribute.\n",
        "scalar.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BDaViEPI-FQ",
        "outputId": "a50f666a-bab0-4788-e845-cdfe3ea50561"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To retrieve the number from the tensor, use the `item()` method."
      ],
      "metadata": {
        "id": "jzW_NBE3jGQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Python number (int) within a tensor (only works with one-element tensors)\n",
        "scalar.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-hwUIMNJAf5",
        "outputId": "49034fab-2cad-4b98-e281-e6f3ed5c02de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a Vector\n",
        "\n",
        "A **vector** is a single dimension tensor but can contain many numbers.\n",
        "\n",
        "The important trend here is that a vector is flexible in what it can represent (the same with tensors).\n"
      ],
      "metadata": {
        "id": "zaLUm_TJjan2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector\n",
        "vector = torch.tensor([7,7])\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsNMoU5YKeTE",
        "outputId": "e854a705-394c-48be-dd78-938544fbe6db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of dimensions of vector\n",
        "vector.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmf7xa0sKrqu",
        "outputId": "b07befb1-b09f-4b2c-838f-9ee23f22e50c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of **dimensions** a tensor in PyTorch has by the number of square brackets on the outside ([) and you only need to count one side.\n",
        "\n",
        "`shape` attribute - how the elements inside them are arranged."
      ],
      "metadata": {
        "id": "TdOs8i5fj4iY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shape of vector\n",
        "vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDFnpPPHKuQV",
        "outputId": "d42fcb7c-e4fd-4b1c-eb68-070358cbae9f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above returns torch.Size([2]) which means our vector has a shape of [2]. This is because of the two elements we placed inside the square brackets ([7, 7])."
      ],
      "metadata": {
        "id": "sDBM1g6mks8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MATRIX\n",
        "MATRIX = torch.tensor([[7,8],\n",
        "                      [9,10]])\n",
        "MATRIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzFs79fYKzI1",
        "outputId": "09600c6d-2942-46e9-8ee9-afdd1582cc74"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrices are as flexible as vectors, except they've got an extra dimension."
      ],
      "metadata": {
        "id": "2udHJwGSkypl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check number of dimensions\n",
        "MATRIX.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYZF6_wLLCAr",
        "outputId": "a049c1c8-bdc4-4f42-afd9-f698abda9e59"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AQLUubELFvu",
        "outputId": "f1f3b573-ca09-4fd5-aecb-3741ffd69600"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output is `torch.Size([2, 2])` because MATRIX is two elements deep and two elements wide."
      ],
      "metadata": {
        "id": "M42jrSQ-mxqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a tensor\n",
        "\n",
        "Tensors can represent almost anything"
      ],
      "metadata": {
        "id": "gIJZpXCsm7c2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor\n",
        "TENSOR = torch.tensor([[[1,2,3],\n",
        "                        [3,6,9],\n",
        "                        [2,4,5]]])\n",
        "TENSOR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF39o2t-LNyc",
        "outputId": "6c1feb44-d350-469b-a522-0b9f41d62c58"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [3, 6, 9],\n",
              "         [2, 4, 5]]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check number of dimensions for TENSOR\n",
        "TENSOR.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTEV_T64Ldhh",
        "outputId": "b0e5474c-22b4-45a0-ea35-e1738f9f45af"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shape of TENSOR\n",
        "TENSOR.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xg9LjsALh7j",
        "outputId": "1befda2a-e3cd-42e4-fac4-e46901979ae4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dimensions go outer to inner.\n",
        "\n",
        "So the output: `torch.Size([1, 3, 3])` means there's 1 dimension of 3 by 3.\n",
        "\n",
        "![example of different tensor dimensions](https://raw.githubusercontent.com/jiayinjx/pytorch-machine-learning/main/images/00-pytorch-different-tensor-dimensions.png)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "3m9qurpGoGdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI4kXtIfLbIQ",
        "outputId": "55a37376-a990-4f1d-ced5-a0fff2a96c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [3, 6, 9],\n",
              "        [2, 4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summary\n",
        "\n",
        "| Name | What is it? | Number of dimensions | Lower or upper (usually/example) |\n",
        "| ----- | ----- | ----- | ----- |\n",
        "| **scalar** | a single number | 0 | Lower (`a`) |\n",
        "| **vector** | a number with direction (e.g. wind speed with direction) but can also have many other numbers | 1 | Lower (`y`) |\n",
        "| **matrix** | a 2-dimensional array of numbers | 2 | Upper (`Q`) |\n",
        "| **tensor** | an n-dimensional array of numbers | can be any number, a 0-dimension tensor is a scalar, a 1-dimension tensor is a vector | Upper (`X`) |\n",
        "\n",
        "![scalar vector matrix tensor and what they look like](https://raw.githubusercontent.com/jiayinjx/pytorch-machine-learning/main/images/00-scalar-vector-matrix-tensor.png)"
      ],
      "metadata": {
        "id": "-2ZbGwMZskYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random tensors\n",
        "\n",
        "Why random tensors?\n",
        "\n",
        "Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
        "\n",
        "`Start with random numbers -> look at data -> update random nubmers -> look at data -> update random nubmers...`\n",
        "\n",
        "As a data scientist, we can define how the machine learning model starts (initialization), looks at data (representation) and updates (optimization) its random numbers.\n",
        "\n",
        "Using [`torch.rand()`](https://pytorch.org/docs/stable/generated/torch.rand.html) and passing in the `size` parameter."
      ],
      "metadata": {
        "id": "tZ7fHgGvMAQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor of shape/size (3, 4)\n",
        "random_tensor = torch.rand(3, 4) # similar to torch.rand(size=(3, 4))\n",
        "random_tensor, random_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKEih6o1MbHT",
        "outputId": "e0649287-8fcd-4101-cc64-88c77aa44083"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.4026, 0.1658, 0.8722, 0.3993],\n",
              "         [0.5997, 0.6889, 0.3335, 0.2841],\n",
              "         [0.7274, 0.3506, 0.5579, 0.3389]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R0Yi_ASNNK0",
        "outputId": "0e7b5fd0-c047-4edf-f69e-e91af3ab8b32"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example: we can create a random tensor in the common image shape of [224, 224, 3] ([height, width, color_channels])."
      ],
      "metadata": {
        "id": "94doCPUSujkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor with similar shape to an image tensor\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3)) # ([height, width, color channel])\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CDEmVapNNSB",
        "outputId": "2d6c974e-36ef-4e1a-e3ee-53469ebc332c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zeros and ones"
      ],
      "metadata": {
        "id": "cQ6WRMTlNNYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all zeros\n",
        "zeros = torch.zeros(size=(3,4))\n",
        "zeros, zeros.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX2Epj51ObKq",
        "outputId": "10cd3cf2-cabc-49aa-d38c-14b73f1ec7c0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeros * random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6Vy_7n7OhY-",
        "outputId": "4c5a0e13-7297-409c-80a5-d7c5a2772c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.ones(size=(3,4))\n",
        "ones, ones.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y31cD0OfOmNq",
        "outputId": "868e51fe-e48b-4bca-e169-938116d7302b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a range of tensor and tensors-like\n",
        "\n",
        "Using `torch.arange(start, end, step)`."
      ],
      "metadata": {
        "id": "v7Dkh0wxPFDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use torch.range() and get deprecated message, use torch.arange()\n",
        "one_to_ten = torch.arange(1,11,1) # start, end, step\n",
        "# one_to_ten = torch.arange(start=1, end=11, step=1)\n",
        "one_to_ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY4e6RMvPKrs",
        "outputId": "feff8fcb-b6e9-4644-ee7b-c1ca8b35396e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes we want one tensor of a certain type with the same shape as another tensor.\n",
        "\n",
        "For example, a tensor of all zeros with the same shape as a previous tensor.\n",
        "\n",
        "Using [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) or [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) which return a tensor filled with zeros or ones in the same shape as the `input` respectively."
      ],
      "metadata": {
        "id": "Z8h13NDByd3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of zeros similar to another tensor\n",
        "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
        "ten_zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApDWrSq-PS6n",
        "outputId": "e9738ffb-9d55-4ce7-bf5c-2e3a13fce6ff"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor datatypes\n",
        "\n",
        "Different [tensor datatypes available in PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
        "\n",
        "Some are specific for CPU and some are better for GPU.\n",
        "\n",
        "Generally if you see `torch.cuda` anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).\n",
        "\n",
        "The most common type (and generally the default) is `torch.float32` or `torch.float` (referred to as \"32-bit floating point\"), 16-bit floating point (`torch.float16` or `torch.half`) and 64-bit floating point (`torch.float64` or `torch.double`).\n",
        "> Example: `Single-precision floating-point (float32)` is a computer number format, usually occupying 32 bits in computer memory.\n",
        "\n",
        "There is also 8-bit, 16-bit, 32-bit and 64-bit integers.\n",
        "\n",
        "\n",
        "> **Note:** An integer is a flat round number like `7` whereas a float has a decimal `7.0`.\n",
        "\n",
        "The reason for all of these is to do with **precision in computing**.\n",
        "\n",
        "Precision is the amount of detail used to describe a number.\n",
        ">The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
        ">\n",
        "> Lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics like accuracy (faster to compute but less accurate).\n",
        ">\n",
        "\n",
        "**Resources:**\n",
        "- See the [PyTorch documentation for a list of all available tensor datatypes](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
        "- Read the [Wikipedia page for an overview of what precision in computing is](https://en.wikipedia.org/wiki/Precision_(computer_science).\n"
      ],
      "metadata": {
        "id": "-XfdQevPQbaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Default datatype for tensors is float32\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None, # what datatype is the tensor (e.g. float32 or float16, defaults to None)\n",
        "                               device=None, # what device is your tensor on (e.g. cpu, cuda, defaults to None)\n",
        "                               requires_grad=False) # whether or not to track gradients with this tensors operations\n",
        "float_32_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EgqpS4MQjHB",
        "outputId": "cfdc6efa-2bc7-4c4f-d782-0f543f91a444"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq0Srx2GQqXT",
        "outputId": "24b495f2-1717-418e-9963-c8013d80367d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.float32, device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# float_16_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=torch.float16)\n",
        "float_16_tensor = float_32_tensor.type(torch.float16)\n",
        "float_16_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxgu1Pr1QxPh",
        "outputId": "1ad6072f-76aa-431c-a6cd-89f02f069600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor"
      ],
      "metadata": {
        "id": "oIJTbaanStxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor * float_32_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8D_xQuATKno",
        "outputId": "42586776-f47f-4faf-f76e-5e6f014ba42e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int_32_tensor = torch.tensor([3,6,9],\n",
        "                             dtype=torch.int32)\n",
        "int_32_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TriPtxPTLtW",
        "outputId": "0dcee659-b8c0-4cef-81ef-ba7408143063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 6, 9], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int_32_tensor * float_16_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qoiekPFTsoW",
        "outputId": "ffb93920-f72a-4718-e15f-27dc2e469f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with PyTorch & Deep Learning:\n",
        "1. Tensors not right datatype - to get datatype from a tensor, can use `tensor.dtype`  \n",
        "2. Tensors not right shape - to get shape from a tensor, can use `tensor.shape`  \n",
        "3. Tensors not on the right device - to get device from a tensor, can use `tensor.device`"
      ],
      "metadata": {
        "id": "DpvE07vI68Z_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting information from tensors (tensor attributes)\n",
        "\n",
        "Three of the most common attributes:\n",
        "* `shape` - what shape is the tensor? (some operations require specific shape rules)\n",
        "* `dtype` - what datatype are the elements within the tensor stored in?\n",
        "* `device` - what device is the tensor stored on? (usually GPU or CPU)\n",
        "\n",
        "Let's create a random tensor and find out details about it."
      ],
      "metadata": {
        "id": "V8-BUSq0TL31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor\n",
        "some_tensor = torch.rand(3, 4)\n",
        "\n",
        "# Find out details about it\n",
        "print(some_tensor)\n",
        "print(f\"\\nSize of tensor: {some_tensor.size}\") # size is function\n",
        "print(f\"Size of tensor: {some_tensor.size()}\") # size is function\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\") # shape is an attribute)\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsiszoUZUcAq",
        "outputId": "7a6e9f59-44e7-4baa-e01a-43763e8f5576"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7303, 0.9877, 0.3740, 0.7529],\n",
            "        [0.5452, 0.9145, 0.5050, 0.9066],\n",
            "        [0.1868, 0.4628, 0.0232, 0.7110]])\n",
            "\n",
            "Size of tensor: <built-in method size of Tensor object at 0x7d2af1d0ecf0>\n",
            "Size of tensor: torch.Size([3, 4])\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manipulating Tensors (tensor operations)\n",
        "\n",
        "Tensor operations include:\n",
        "* Addition\n",
        "* Substraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix multiplication"
      ],
      "metadata": {
        "id": "-AJVoey2VhXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic operations\n",
        "\n",
        "Addition (`+`), subtraction (`-`), mutliplication (`*`)."
      ],
      "metadata": {
        "id": "dNEKtyxV8UpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of values and add a number to it\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_8Q_jhDVhd6",
        "outputId": "4cb72d23-272f-402a-c3a4-6a85e984c505"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiply the tensor by 10\n",
        "tensor * 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IBZocswWHVc",
        "outputId": "ce138246-ddf3-4882-cf40-0fb909f64111"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notice** how the tensor values above didn't end up being tensor([110, 120, 130]), this is because the values inside the tensor don't change unless they're reassigned."
      ],
      "metadata": {
        "id": "tfgPjoQh8vbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Substract and reassign\n",
        "tensor = tensor - 10\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMIPBxgKVhj3",
        "outputId": "ad5204eb-1aeb-4d0e-ab33-274ef3a3b39d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add and reassign\n",
        "tensor = tensor + 10\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDRFx9vA9nsn",
        "outputId": "506a56e7-9f5c-46b3-f9cc-e6451e2c517b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Built-in functions in PyTorch like:\n",
        "- [`torch.mul()`](https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul) (short for multiplication)\n",
        "- [`torch.add()`](https://pytorch.org/docs/stable/generated/torch.add.html) to perform basic operations."
      ],
      "metadata": {
        "id": "x8Pet_Fd9DWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try out PyTorch in-built functions\n",
        "torch.mul(tensor, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssa8xXrVVhpT",
        "outputId": "ce0cb6db-925d-48ee-9941-a0404acf220b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.add(tensor, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73XKocNH9e0o",
        "outputId": "62faac3d-5097-4a30-e26b-b3b92189053a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original tensor is still unchanged\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl_Syq6g9ipz",
        "outputId": "4e7f2f41-9c2c-41e4-a7db-ac04591bd79d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the operator symbols like `*` instead of `torch.mul()`."
      ],
      "metadata": {
        "id": "BZxRaPb_9gnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Element-wise multiplication (each element multiplies its equivalent, index 0->0, 1->1, 2->2)\n",
        "print(tensor, \"*\", tensor)\n",
        "print(\"Equals:\", tensor * tensor)"
      ],
      "metadata": {
        "id": "r2PGWG3P93ia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1424ecb3-08e9-43eb-b223-bd566a3e38e1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "Equals: tensor([1, 4, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix multiplication\n",
        "\n",
        "One of the most common operations in machine learning and deep learning algorithms (like neural networks) is [matrix multiplication](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
        "\n",
        "PyTorch implements matrix multiplication functionality in the [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html) method.\n",
        "\n",
        "Two main ways of performing multiplication in neural networks & deep learning:\n",
        "1. ELement-wise multiplication\n",
        "2. Matrix multiplication (dot product)\n",
        "\n",
        "There are two main rules that performing matrix mutliplication needs to satisfy:\n",
        "1. The **inner dimensions** must match:\n",
        "* `(3, 2) @ (3, 2)` won't work\n",
        "* `(2, 3) @ (3, 2)` will work\n",
        "* `(3, 2) @ (2, 3)` will work\n",
        "2. The resulting matrix has the shape of the **outer dimensions**:\n",
        "* `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
        "* `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
        "\n",
        "> **Note:** \"`@`\" in Python is the symbol for matrix multiplication.\n",
        "\n",
        "> **Resource:** See all of the rules for matrix multiplication using `torch.matmul()` [in the PyTorch documentation](https://pytorch.org/docs/stable/generated/torch.matmul.html)."
      ],
      "metadata": {
        "id": "NQCKvgCmVhya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5Rhi9iDHpqx",
        "outputId": "03e0f93f-8225-4aa4-8642-01281d1d2e93"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between element-wise multiplication and matrix multiplication is the addition of values.\n",
        "\n",
        "For our `tensor` variable with values `[1, 2, 3]`:\n",
        "\n",
        "| Operation | Calculation | Code |\n",
        "| ----- | ----- | ----- |\n",
        "| **Element-wise multiplication** | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `tensor * tensor` |\n",
        "| **Matrix multiplication** | `[1*1 + 2*2 + 3*3]` = `[14]` | `tensor.matmul(tensor)` |\n"
      ],
      "metadata": {
        "id": "KMFviQ_z-0dR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ELement-wise multiplication\n",
        "print(tensor, \"*\", tensor)\n",
        "print(f\"Equals: {tensor * tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twxWgEgbXbuA",
        "outputId": "08781661-2954-467f-d529-3e6c6a6a1ea4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "Equals: tensor([1, 4, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication (dot product)\n",
        "torch.matmul(tensor, tensor) # similar to tensor @ tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XPPs-ZSXb4P",
        "outputId": "9ec64f4d-7363-4484-92d9-aa3cf7da961c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.matmul(torch.rand(3,2), torch.rand(3,2))\n",
        "# RuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)\n",
        "\n",
        "print(torch.matmul(torch.rand(3,2), torch.rand(2,3)))\n",
        "\n",
        "print(torch.matmul(torch.rand(3,10), torch.rand(10,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtDOOTgd_EkE",
        "outputId": "fbf279b9-b018-45b1-ead8-904b60b2107d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5404, 0.6417, 0.3646],\n",
            "        [0.9651, 1.1647, 0.6929],\n",
            "        [0.7950, 0.9521, 0.5544]])\n",
            "tensor([[2.3086, 1.9185, 1.6808],\n",
            "        [2.8521, 1.7292, 1.9919],\n",
            "        [3.1428, 1.8459, 2.0707]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication by hand\n",
        "1*1 + 2*2 + 3*3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7cNzeCSYaG4",
        "outputId": "afa074b9-fe01-444c-85a9-e91f21c0831e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "  value += tensor[i] * tensor[i]\n",
        "print(value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8kPufJCXb_L",
        "outputId": "966444af-2098-4baa-e9d1-efba91bad3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(14)\n",
            "CPU times: user 2.61 ms, sys: 0 ns, total: 2.61 ms\n",
            "Wall time: 7.42 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJR2zYf2XcFT",
        "outputId": "c72f6b1a-3313-4e16-82b4-c368bd350e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 507 µs, sys: 91 µs, total: 598 µs\n",
            "Wall time: 9.78 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One of the most common erros in deep learning: shape errors\n",
        "\n",
        "Because much of deep learning is multiplying and performing operations on matrices and matrices have a strict rule about what shapes and sizes can be combined, one of the most common errors you'll run into in deep learning is shape mismatches."
      ],
      "metadata": {
        "id": "kYieiJL1XcKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shapes for matrix multiplication\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]])\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]])\n",
        "torch.mm(tensor_A, tensor_B) # torch.mm is the same as torch.matmul (it's an alias for writing less code)\n",
        "torch.matmul(tensor_A, tensor_B) # (this will error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "ysQdoYyMXcQo",
        "outputId": "a40d0ed3-75bf-4a28-dea3-5fd7c49b187d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b7cebbc12ade>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                          \u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                          [9, 12]])\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_B\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# torch.mm is the same as torch.matmul (it's an alias for writing less code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_A.shape, tensor_B.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpE8tVIrIg4o",
        "outputId": "34666940-f10b-41e9-990d-eac0cc3442b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 2]), torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**.\n",
        "\n",
        "A **transpose** switches the axes or dimensions of a given tensor."
      ],
      "metadata": {
        "id": "c8UlbEujIhAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_B, tensor_B.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFCJP6y7XcVy",
        "outputId": "ba1ade01-c006-4f12-d52e-a9b4650a107a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 7, 10],\n",
              "         [ 8, 11],\n",
              "         [ 9, 12]]),\n",
              " torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_B.T, tensor_B.T.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ivxn3RFYIhGK",
        "outputId": "a4dd34f1-933d-438c-df3f-6d92e5a715f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 7,  8,  9],\n",
              "         [10, 11, 12]]),\n",
              " torch.Size([2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The matrix multiplication operation owrks when tensor_B is transposed.\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same shape as above), tensor_B.T = {tensor_B.T.shape}\")\n",
        "print(f\"Multiplying: {tensor_A.shape} @ {tensor_B.T.shape} <- inner dimensions much match\")\n",
        "\n",
        "print(\"\\nOutput:\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rwNkQguKBai",
        "outputId": "26cce5a4-4e54-4cf1-908a-0f7d057bc7c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same shape as above), tensor_B.T = torch.Size([2, 3])\n",
            "Multiplying: torch.Size([3, 2]) @ torch.Size([2, 3]) <- inner dimensions much match\n",
            "\n",
            "Output:\n",
            "tensor([[ 27,  30,  33],\n",
            "        [ 61,  68,  75],\n",
            "        [ 95, 106, 117]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without the transpose, the rules of matrix mulitplication aren't fulfilled and we get an error like above.\n",
        "\n",
        "How about a visual?\n",
        "\n",
        "![visual demo of matrix multiplication](https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/00-matrix-multiply-crop.gif)\n",
        "\n",
        "You can create your own matrix multiplication visuals like this at http://matrixmultiplication.xyz/.\n",
        "\n",
        "> **Note:** A matrix multiplication like this is also referred to as the [**dot product**](https://www.mathsisfun.com/algebra/vectors-dot-product.html) of two matrices.\n"
      ],
      "metadata": {
        "id": "GQBN_A_bNlld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the min, max, mean, sum, etc (tensor aggregation)"
      ],
      "metadata": {
        "id": "tfCw6LsxKBjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(1, 100, 10)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zcf5XPttKBqQ",
        "outputId": "30a9c060-f1a7-4204-91d9-930f9a360af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the min\n",
        "torch.min(x), x.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMK8HXejKBwE",
        "outputId": "09097459-a8fd-4538-9931-6d7a0bb3ed51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1), tensor(1))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the max\n",
        "torch.max(x), x.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOa_rOkkOyp2",
        "outputId": "b8d1e9dd-874a-47ec-a0f7-b71738d10b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(91), tensor(91))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the mean\n",
        "torch.mean(x) # (this will error)\n",
        "# RuntimeError: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long\n",
        "# int64 is a Long"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "xzVbhRVJO2w_",
        "outputId": "e171de01-0cad-4154-be43-79c2f01f20a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-ac7835a122a3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Find the mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (this will error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# RuntimeError: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# int64 is a Long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: the torch.mean() function requires a tensor of float32 datatype to work.\n",
        "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSJifPutPTzi",
        "outputId": "39a54008-aae7-4c07-dbe9-cd527cd04400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(46.), tensor(46.))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the sum\n",
        "torch.sum(x), x.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eCSZStWP257",
        "outputId": "3ab86718-804e-4d64-fcd7-c1d955d33adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(460), tensor(460))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the positional min and max"
      ],
      "metadata": {
        "id": "v_2sVLPPQHyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsyFI76BQH4z",
        "outputId": "9e3e4186-9802-4024-849b-d950ba28a5c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the position in tensor that has the minimum value with argmin() -> returns index position of target tensor where the minimum value occues.\n",
        "x.argmin()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83ZggcutQH90",
        "outputId": "7b21c0ac-ca04-4228-fea1-f52c5ecf66a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQy2cQQ1Qnrr",
        "outputId": "60fba281-2a82-46e1-ef27-050c5784291a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the position in tensor that has the maximum value with argmax()\n",
        "x.argmax()"
      ],
      "metadata": {
        "id": "0-rnWLGwQzvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd5b45a3-dcdf-47dd-a228-6b8e9f268551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnN9AoIFRGhy",
        "outputId": "b04da614-5c4f-4b3e-b746-d69d19f383a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(91)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
        "\n",
        "* Reshaping - reshapes an input tensor to a defined shape\n",
        "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
        "* Stacking - Combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
        "* Squeeze - Removes all `1` dimensions from a tensor\n",
        "* Unsqueeze - Add a `1` dimension to a target tensor\n",
        "* Permute - Return a view of the input with dimensions permuted (sqapped) in a certain way\n",
        "\n",
        "| Method | One-line description |\n",
        "| ----- | ----- |\n",
        "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | Reshapes `input` to `shape` (if compatible), can also use `torch.Tensor.reshape()`. |\n",
        "| [`Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Returns a view of the original tensor in a different `shape` but shares the same data as the original tensor. |\n",
        "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Concatenates a sequence of `tensors` along a new dimension (`dim`), all `tensors` must be same size. |\n",
        "| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | Squeezes `input` to remove all the dimenions with value `1`. |\n",
        "| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | Returns `input` with a dimension value of `1` added at `dim`. |\n",
        "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Returns a *view* of the original `input` with its dimensions permuted (rearranged) to `dims`. |"
      ],
      "metadata": {
        "id": "6cQGf4vKRImm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1., 10.)\n",
        "x, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EALjzPphRItX",
        "outputId": "55debf02-630b-44b4-8b48-b0805704dfab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra dimension\n",
        "x_reshaped = x.reshape(3, 3)\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT_sd8qBRIy6",
        "outputId": "b4d30d5a-5c50-4f46-e493-9d36e3c7b87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3.],\n",
              "         [4., 5., 6.],\n",
              "         [7., 8., 9.]]),\n",
              " torch.Size([3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_reshaped = x.reshape(1, 9)\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG2aQxeOULgr",
        "outputId": "e07909f0-d7ba-4487-fc34-ab52a7f4c86b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the view\n",
        "z = x.view(1, 9)\n",
        "z, z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nM_Mw9lRI4e",
        "outputId": "140fbcf6-f193-4263-b0f5-bd63996533e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing z changes x (because a view of a tensor shares the same memroy as the original input)\n",
        "# See more: https://stackoverflow.com/a/54507446/7900723\n",
        "z[:, 0] = 5\n",
        "z, x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOYQZOcSUo8h",
        "outputId": "138679e0-64c3-4c8f-f306-223457044678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
              " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack tensors on top of each other\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
        "x_stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkwGbgV2VmYf",
        "outputId": "7b570a03-0d81-40b9-b1d1-b55ad82bd595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_stacked = torch.stack([x, x, x, x], dim=1)\n",
        "x_stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bjXU-_MVmfP",
        "outputId": "031ec189-10b2-43d5-8e7d-fb0cba0b3de3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 5., 5., 5.],\n",
              "        [2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3.],\n",
              "        [4., 4., 4., 4.],\n",
              "        [5., 5., 5., 5.],\n",
              "        [6., 6., 6., 6.],\n",
              "        [7., 7., 7., 7.],\n",
              "        [8., 8., 8., 8.],\n",
              "        [9., 9., 9., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_stacked = torch.stack([x, x, x, x], dim=-2)\n",
        "x_stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz-EBatSUpHy",
        "outputId": "b3af632d-d6f1-4d86-ebd9-90a9e7441faf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([4, 5, 6])\n",
        "a_b_stack = torch.stack((a,b))\n",
        "print(a_b_stack)\n",
        "a_b_hstack = torch.hstack((a,b))\n",
        "print(a_b_hstack)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6Fhfd3CYE2w",
        "outputId": "36a0a738-1920-4dce-a0eb-b4f247954a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([1, 2, 3, 4, 5, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.squeeze() - removes all single dimensions from a target tensor\n",
        "\n",
        "print(f\"Previous tensor: {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped.shape}\")\n",
        "\n",
        "# Remove extra dimension from x_reshaped\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {x_squeezed}\")\n",
        "print(f\"New shape: {x_squeezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YdSwVPeYwc6",
        "outputId": "dcac095d-5915-47e8-9680-8571e1f7080c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "Previous shape: torch.Size([1, 9])\n",
            "\n",
            "New tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "New shape: torch.Size([9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_reshaped.squeeze(), x_reshaped.squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87KPphzkYwng",
        "outputId": "bd18b2bf-5fa7-4d78-a0fa-cea8591867c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.unsqueeze() - adds a single dimension to a taget tensor at a specific dim (dimension).\n",
        "\n",
        "print(f\"Previous tensor: {x_squeezed}\")\n",
        "print(f\"Previous shape: {x_squeezed.shape}\")\n",
        "\n",
        "## Add an extra dimension with unsqueeze\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snRo6GlNYwwW",
        "outputId": "50ec9bf1-bd43-4359-9e80-d276304df41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "Previous shape: torch.Size([9])\n",
            "\n",
            "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "New shape: torch.Size([1, 9])\n"
          ]
        }
      ]
    }
  ]
}